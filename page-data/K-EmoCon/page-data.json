{"componentChunkName":"component---src-templates-blog-post-js","path":"/K-EmoCon/","result":{"data":{"site":{"siteMetadata":{"title":"Human-AI Interaction Lab"}},"markdownRemark":{"id":"0f48903e-97d1-5482-ab68-27a22d29f88d","excerpt":"K-EmoCon, a Multimodal Sensor Dataset for Continuous Emotion Recognition in Naturalistic Conversations Abstract Recognizing emotions during social interactionsâ€¦","html":"<h1>K-EmoCon, a Multimodal Sensor Dataset for Continuous Emotion Recognition in Naturalistic Conversations</h1>\n<h2>Abstract</h2>\n<p>Recognizing emotions during social interactions has many potential applications with the popularization of low-cost mobile sensors, but a challenge remains with the lack of naturalistic affective interaction data. Most existing emotion datasets do not support studying idiosyncratic emotions arising in the wild as they were collected in constrained environments.</p>\n<p>Therefore, studying emotions in the context of social interactions requires a novel dataset, and K-EmoCon is such a multimodal dataset with comprehensive annotations of continuous emotions during naturalistic conversations.</p>\n<h2>Dataset Overview</h2>\n<p>The dataset contains multimodal measurements, including:</p>\n<ul>\n<li><strong>Audiovisual recordings</strong></li>\n<li><strong>EEG (Electroencephalography)</strong></li>\n<li><strong>Peripheral physiological signals</strong></li>\n</ul>\n<p>All data was acquired with off-the-shelf devices from 16 sessions of approximately 10-minute long paired debates on a social issue.</p>\n<h2>Key Features</h2>\n<p>Distinct from previous datasets, K-EmoCon includes emotion annotations from all three available perspectives, providing comprehensive coverage of emotional states during naturalistic conversations.</p>\n<h2>Research Applications</h2>\n<p>This dataset enables research in:</p>\n<ol>\n<li><strong>Continuous emotion recognition</strong> in naturalistic settings</li>\n<li><strong>Multimodal emotion analysis</strong> using various sensor data</li>\n<li><strong>Social interaction emotion modeling</strong></li>\n<li><strong>Real-world affective computing</strong> applications</li>\n</ol>\n<h2>Dataset Specifications</h2>\n<ul>\n<li><strong>Sessions</strong>: 16 debate sessions</li>\n<li><strong>Duration</strong>: ~10 minutes per session</li>\n<li><strong>Participants</strong>: Paired debates on social issues</li>\n<li><strong>Sensors</strong>: Off-the-shelf devices for accessibility</li>\n<li><strong>Annotations</strong>: Comprehensive emotion labels from multiple perspectives</li>\n</ul>\n<h2>Impact</h2>\n<p>K-EmoCon addresses the critical gap in naturalistic emotion datasets, enabling researchers to study emotions in real-world social interactions rather than constrained laboratory settings. This dataset has been widely cited (197 citations) and has significantly advanced the field of affective computing.</p>\n<h2>Publication Details</h2>\n<ul>\n<li><strong>Journal</strong>: Scientific Data (Nature)</li>\n<li><strong>Volume</strong>: 7</li>\n<li><strong>Issue</strong>: 1</li>\n<li><strong>Publisher</strong>: Nature Publishing Group</li>\n<li><strong>Publication Date</strong>: September 8, 2020</li>\n</ul>\n<h2>Citation</h2>\n<p>Park, C.Y., Cha, N., Kang, S. et al. K-EmoCon, a multimodal sensor dataset for continuous emotion recognition in naturalistic conversations. Sci Data 7, 285 (2020). <a href=\"https://doi.org/10.1038/s41597-020-00630-y\">https://doi.org/10.1038/s41597-020-00630-y</a></p>","frontmatter":{"title":"K-EmoCon, a Multimodal Sensor Dataset for Continuous Emotion Recognition in Naturalistic Conversations","date":"September 08, 2020","description":null}},"previous":{"fields":{"slug":"/Smart-speaker-timing/"},"frontmatter":{"title":"Hello there! is now a good time to talk? Opportune moments for proactive interactions with smart speakers"}},"next":{"fields":{"slug":"/Driver-vehicle-flow-control/"},"frontmatter":{"title":"Towards Flow Control of Driver-Vehicle Interactions"}}},"pageContext":{"id":"0f48903e-97d1-5482-ab68-27a22d29f88d","previousPostId":"59d50222-d429-5855-86c3-0809b6fc8714","nextPostId":"e6f71382-5298-5119-8c69-c45e0d9e00a6"}},"staticQueryHashes":["1130308659","2841359383"],"slicesMap":{}}