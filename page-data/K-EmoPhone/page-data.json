{"componentChunkName":"component---src-templates-blog-post-js","path":"/K-EmoPhone/","result":{"data":{"site":{"siteMetadata":{"title":"Human-AI Interaction Lab"}},"markdownRemark":{"id":"ed948b8c-9aab-59e9-9622-fd1fc7e43f0b","excerpt":"K-EmoPhone: A Mobile and Wearable Dataset with In-Situ Emotion, Stress, and Attention Labels Abstract With the popularization of low-cost mobile and wearableâ€¦","html":"<h1>K-EmoPhone: A Mobile and Wearable Dataset with In-Situ Emotion, Stress, and Attention Labels</h1>\n<h2>Abstract</h2>\n<p>With the popularization of low-cost mobile and wearable sensors, several studies have used them to track and analyze mental well-being, productivity, and behavioral patterns. However, there is still a lack of open datasets collected in real-world contexts with affective and cognitive state labels such as emotion, stress, and attention; the lack of such datasets limits research advances in affective computing and human-computer interaction.</p>\n<p>This study presents K-EmoPhone, a real-world multimodal dataset collected from 77 students over seven days. This dataset contains:</p>\n<ol>\n<li><strong>Continuous probing of peripheral physiological signals and mobility data</strong> measured by commercial off-the-shelf devices</li>\n<li><strong>Context and interaction data</strong> collected from individuals' smartphones</li>\n<li><strong>5,582 self-reported affect states</strong>, including emotions, stress, attention, and task disturbance, acquired by the experience sampling method</li>\n</ol>\n<h2>Dataset Overview</h2>\n<ul>\n<li><strong>Participants</strong>: 77 students</li>\n<li><strong>Duration</strong>: 7 days per participant</li>\n<li><strong>Affect Labels</strong>: 5,582 self-reported states</li>\n<li><strong>Data Types</strong>: Physiological signals, mobility data, smartphone interaction data</li>\n<li><strong>Collection Method</strong>: Experience sampling method (ESM)</li>\n</ul>\n<h2>Key Contributions</h2>\n<ul>\n<li>First large-scale real-world dataset with in-situ emotion, stress, and attention labels</li>\n<li>Multimodal data collection from mobile and wearable devices</li>\n<li>Comprehensive affect state annotations through experience sampling</li>\n<li>Enables research advances in affective computing and human-computer interaction</li>\n</ul>\n<h2>Impact</h2>\n<p>This dataset addresses the critical gap in open datasets for affective computing research, providing researchers with real-world multimodal data to advance understanding of human emotional and cognitive states in naturalistic settings.</p>\n<h2>Citation</h2>\n<p>Kang, S., Choi, W., Park, C.Y. et al. K-EmoPhone: A mobile and wearable dataset with in-situ emotion, stress, and attention labels. Sci Data 10, 351 (2023). <a href=\"https://doi.org/10.1038/s41597-023-02253-5\">https://doi.org/10.1038/s41597-023-02253-5</a></p>","frontmatter":{"title":"K-EmoPhone: A Mobile and Wearable Dataset with In-Situ Emotion, Stress, and Attention Labels","date":"June 02, 2023","description":null}},"previous":{"fields":{"slug":"/Endpoint-device-risk-scoring/"},"frontmatter":{"title":"Endpoint Device Risk-Scoring Algorithm Proposal for Zero Trust"}},"next":{"fields":{"slug":"/ai-complaint-classification/"},"frontmatter":{"title":"AI Complaint Classification for University IT Services"}}},"pageContext":{"id":"ed948b8c-9aab-59e9-9622-fd1fc7e43f0b","previousPostId":"d9a6c30e-d840-5b95-99d4-e44294ac78e5","nextPostId":"3ab70880-96e0-5d63-9631-8a240baf1ebb"}},"staticQueryHashes":["1130308659","2841359383"],"slicesMap":{}}